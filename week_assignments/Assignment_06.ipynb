{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Assignment 06 Data processing algorithms\n\nIn this assignment, you will be designing and implementing algorithms for a data processing tasks. The Assignment does not include a visualization this week.\n\nOne of the algoritms is the MapReduce algorithm. The MapReduce programming model (and a corresponding system) was proposed in a 2004 paper from a team at Google as a simpler abstraction for processing very large datasets in parallel. The goal of this assignment is to give you experience “thinking in MapReduce.” We will be using small datasets that you can inspect directly to determine the correctness of your results and to internalize how MapReduce works. In the next semsester, you will process the very large datasets for which it was designed.\n\n\n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Part 1: Benchmark algorithm\n\nGo to https://www.geeksforgeeks.org/sorting-algorithms/. Choose a few algorithms to test. Code them and test them.\n\nYou can also use as a test case a file to match a sequence. In the `/data` section you can find sample data. Implement several find algoritms each using a different sort algorithms. Time the executions of each algortithm. In notebook you can use the magic `%time` to time the function. \n\nAnother option is to use code from your project. Use the sort case of your project and choos several algorithms to benchmark"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Part 2: MapReduce\n\nBelow you find the some basic code for a MapReduce class in python"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import json\nimport sys \n\nclass MapReduce:\n    def __init__(self):\n        self.intermediate = {}\n        self.result = []\n\n    def emit_intermediate(self, key, value):\n        self.intermediate.setdefault(key, [])\n        self.intermediate[key].append(value)\n\n    def emit(self, value):\n        self.result.append(value) \n\n    def execute(self, data, mapper, reducer):\n        for line in data:\n            record = json.loads(line)\n            mapper(record)\n\n        for key in self.intermediate:\n            reducer(key, self.intermediate[key])\n        \n        #this should be overwritten with the actual action to do with the output\n        for item in self.result:\n            pass\n            # print, write or do something to output\n                        ",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "One can use the MapReduce class by writing a specific mapper and a specific reducer function"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "def mapper(record):\n    value = 0 # some map function of record\n    mr.emit_intermediate(value, 1) #emit the intermediate value \n\ndef reducer(key, list_of_values):\n    result = 0 # sme reduce function\n    mr.emit((result)) #emit the result\n    \n## Basic usage example\nmr = MapReduce()\nmr.execute('path_to_data', mapper, reducer)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Code it\n\nIn this assingment we write a MapReduce query in which remove the last 10 characters from each string of nucleotides. Then we remove any duplicates generated.\n\nIn the file `data/dna.json` you find test data with records. Each input record is a 2 element list [sequence id, nucleotides] where sequence id is a string representing a unique identifier for the sequence and nucleotides is a string representing a sequence of nucleotides.\nThis is the file that should go in the mapper. \n\n"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "## Template\n\"\"\"\nUnique trims\nConsider a set of key-value pairs where each key is sequence id and each value is a string of \nnucleotides, e.g., GCTTCCGAAATGCTCGAA....\nRemove the last 10 characters from each string then remove any duplicates.\nusage unique_trimmer.py dna.json\n\"\"\"\nimport MapReduce\n",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Test it\nThe output from the reduce function should be the unique trimmed nucleotide strings.\nYou can verify your outcome with the file `data/unique_trims.json`. Write a `Unit test` for this"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Benchmark it\n\nWrite a benchmark program that times the MapReduce program versus a program that does the same using an ordinary for-loop.\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Expand it\n\nWrite a program that uses fasta files as input creating a trimmed multifasta file using your Map Reduce code"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}