{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Get the data from the web\n\nThe example below extracts data from the web. It uses BeautifulSoup to derive specific parts from the html protocol. In the case below it searches for the html class wikitable from the site https://en.wikipedia.org/wiki/Tilburg_Trappers\n\n    tables = soup.findAll(attrs={'class': re.compile(r\".*\\bwikitable\\b.*\")})\n\nselecting the first which is put in a dataframe. \n    \n\n    "
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "#### !/usr/bin/env python3\n\n__author__ = \"Fenna Feenstra\"\n\nimport urllib.request, urllib.parse, urllib.error\nimport ssl\nfrom bs4 import BeautifulSoup\nimport re\nimport pandas as pd\n\n\ndef hack_ssl():\n    \"\"\" ignores the certificate errors\"\"\"\n    ctx = ssl.create_default_context()\n    ctx.check_hostname = False\n    ctx.verify_mode = ssl.CERT_NONE\n    return ctx\n\n\ndef open_url(url):\n    \"\"\" opens url\"\"\"\n    ctx = hack_ssl()\n    html = urllib.request.urlopen(url, context=ctx).read()\n    return html\n    \n\ndef fetch_tables(html):\n    \"\"\" reads html file as a big string and cleans the html file to make it\n        more readable. input: html, output: tables\n    \"\"\"\n    soup = BeautifulSoup(html, 'html.parser')\n    tables = soup.findAll(attrs={'class': re.compile(r\".*\\bwikitable\\b.*\")})\n    return tables[0]\n\n\ndef table_df(table):\n    \"\"\"parses the html table to a pandas dataframe\"\"\"\n    #fetch dimensions\n    l = len(table.find_all('tr')) \n    w = len(table.find_all('tr')[0].find_all('td'))\n    matrix = [['' for i in range(0,w)] for i in range(0,l)]\n    #fetch content\n    for i, row in enumerate(table.find_all('tr')):\n        for j, column in enumerate(row.find_all('td')):        \n            matrix[i][j]=column.get_text().strip()\n    #put in df making first row the header\n    df = pd.DataFrame(matrix[1:], columns = matrix[0])\n    return df\n\n\ndef main():\n    html = open_url('https://en.wikipedia.org/wiki/Tilburg_Trappers')\n    t = fetch_tables(html)\n    df = table_df(t)\n    print(df)\n    return 0\n\n    \nmain()\n    ",
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "     Season  GP   W OTW OTL   L  Pts   GF   GA              Finish  \\\n0   2018/19  65  44   6   5  10  150  323  174  1st, Oberliga Nord   \n1   2017/18  59  43   8   3   5  110  265  129  1st, Oberliga Nord   \n2   2016/17  60  42   1   3  14  131  263  145  4th, Oberliga Nord   \n3   2015/16  57  40   3   1  11  130  284  119  2nd, Oberliga Nord   \n4   2014/15  24  17   2   0   5   38  126   53     2nd, Eredivisie   \n5   2013/14  36  30   2   4   4   64  216   64     1st, Eredivisie   \n6   2012/13  36  25   2   3   6   82  198   93     2nd, Eredivisie   \n7   2011/12  14  11   0   0   3   80   36   33  3rd, North Sea Cup   \n8   2010/11  28  19   0   1   8  120   70   58  2nd, North Sea Cup   \n9   2009/10  28  17   1   2   8  135   86   55     3rd, Eredivisie   \n10  2008/09  24  18   1   0   5  142   78   56     1st, Eredivisie   \n11  2007/08  24  20   1   0   3  132   58   62     1st, Eredivisie   \n12  2006/07  20  12   1   2   5   88   55   40     2nd, Eredivisie   \n13  2005/06  20   7   1   2  10   70   64   25     6th, Eredivisie   \n\n                                             Playoffs  \n0   Lost Oberliga Championship against EV Landshut...  \n1   Won Oberliga Championship against Deggendorfer...  \n2   Won Oberliga Championship against Tölzer Löwen...  \n3   Won Oberliga Championship against EHC Bayreuth...  \n4   Won Dutch Championship against UNIS Flyers Hee...  \n5   Won Dutch Championship against HYS The Hague (...  \n6                    Lost Finals to The Hague (0W-3L)  \n7                    Lost semi-finals to Geleen (0-3)  \n8                   Lost finals to HYS The Hague(1-4)  \n9                        Lost finals to Nijmegen(0-3)  \n10                     Lost finals to The Hague (2-3)  \n11  Won National Championship against Vadeko Flyer...  \n12  Won National Championship against Vadeko Flyer...  \n13                                    Did not qualify  \n"
        },
        {
          "data": {
            "text/plain": "0"
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Assignment week 01\n\nCheck the site https://www.knmi.nl/nederland-nu/seismologie/aardbevingen\n\nOn this site you find a table of seismologic activities with the following fields.\n\n    Analysis\n    Date and time (UTC)\n    Place\n    Magnitude\n    Depth (km)\n    Type of earthquacke\n    Details\n\nYour job is to fetch the table with the last 15 seismologic activities. Only select the `'Date and Time (UTC)', 'Place', 'Magnitude', 'Depth (km)', 'Type earthquacke'` columns and put it in a pandas dataframe. See example below. "
    },
    {
      "metadata": {},
      "cell_type": "raw",
      "source": "    Date and Time (UTC)           Place Magnitude  Depth (km) Type earthquacke\n0   2019-04-16 02:15:07       Harkstede       0.9         3.0     Geïnduceerd\n1   2019-04-15 07:03:43      Noordwolde       1.6         3.0     Geïnduceerd\n2   2019-04-10 04:40:10       Zuidbroek       1.4         3.0     Geïnduceerd\n3   2019-04-09 19:26:30           Spijk       1.4         3.0     Geïnduceerd\n4   2019-04-07 07:07:33     Garrelsweer       0.9         3.0     Geïnduceerd\n5   2019-03-30 01:51:36      Appingedam       0.5         3.0     Geïnduceerd\n6   2019-03-29 13:37:20         Kantens       1.5         3.0     Geïnduceer\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The data is not clean, since it might contain data from Belgium or Germany. Remove that data. Further more we would like some more insight in the statistics of the data. Calculate the minimum, maximum, mean and standard deviation of the Magnitude using NumPy. Plot the magnitudes choosing a visualisation of your choice."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}