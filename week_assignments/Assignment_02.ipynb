{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Combine data to investigate a hypothesis\n\nThis week we are going to investigate the health risks value of towns. We would like to compare towns that have the most highest temperature with other towns in the Unitied States. The hypothesis is that the health risk value is less for towns with higher temperature compared to ordinary towns. In particular the risk related to 'Adult Binge Drinking'. For this we need two datasets. The dataset of hottest towns and the dataset of USHealth_data.csv. The end goal is to run a hypothesis test of towns in the category 'hot town' compared to 'not hot town'. Before we can do such we first need to clean, organize and merge the data. The column 'Value' for instance contains not all float type data."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Step 1 Fetch and clean hottest towns data\nFetch from \"data/hottest_towns.txt\" a list of hottest towns. The data needs to be put in a DataFrame. The format of the DataFrame should be: \t\n\n    day \tCity \t State\n    107 \tPhoenix   Arizona\n     70     Las Vegas Nevada\n\nThis means that some columns need to be splitted, some rows need to be skipped and some columns need to be renamed.\nsource: https://currentresults.com/Weather-Extremes/US/hottest-cities.php"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def answer_one():\n    pass\n    \ndf = answer_one()\n\ndf",
      "execution_count": 15,
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>City</th>\n      <th>days</th>\n      <th>State</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Austin</td>\n      <td>16</td>\n      <td>Texas</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Dallas</td>\n      <td>17</td>\n      <td>Texas</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Houston</td>\n      <td>4</td>\n      <td>Texas</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Kansas City</td>\n      <td>3</td>\n      <td>Missouri</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Las Vegas</td>\n      <td>70</td>\n      <td>Nevada</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Oklahoma City</td>\n      <td>11</td>\n      <td>Oklahoma</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Phoenix</td>\n      <td>107</td>\n      <td>Arizona</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Riverside</td>\n      <td>24</td>\n      <td>California</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Sacramento</td>\n      <td>11</td>\n      <td>California</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Salt Lake City</td>\n      <td>5</td>\n      <td>Utah</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>San Antonio</td>\n      <td>8</td>\n      <td>Texas</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "              City  days         State\n0           Austin    16        Texas \n1           Dallas    17        Texas \n2          Houston     4        Texas \n3      Kansas City     3     Missouri \n4        Las Vegas    70       Nevada \n5    Oklahoma City    11     Oklahoma \n6          Phoenix   107      Arizona \n7        Riverside    24   California \n8       Sacramento    11   California \n9   Salt Lake City     5         Utah \n10     San Antonio     8        Texas "
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "x = df['City'].unique().tolist()\nx",
      "execution_count": 16,
      "outputs": [
        {
          "data": {
            "text/plain": "['Austin',\n 'Dallas',\n 'Houston',\n 'Kansas City',\n 'Las Vegas',\n 'Oklahoma City',\n 'Phoenix',\n 'Riverside',\n 'Sacramento',\n 'Salt Lake City',\n 'San Antonio']"
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Step 2: fetch the health data\n\nDownload from https://bchi.bigcitieshealth.org/indicators/1892/searches/34591 the complete dataset. Split the Place column into a column \"State\" and a column \"City\". using the dictionary below. "
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Use this dictionary to map state names to two letter acronyms\nstates = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', 'WY': 'Wyoming', 'NA': 'National', 'AL': 'Alabama', 'MD': 'Maryland', 'AK': 'Alaska', 'UT': 'Utah', 'OR': 'Oregon', 'MT': 'Montana', 'IL': 'Illinois', 'TN': 'Tennessee', 'DC': 'District of Columbia', 'VT': 'Vermont', 'ID': 'Idaho', 'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', 'HI': 'Hawaii', 'WI': 'Wisconsin', 'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', 'AZ': 'Arizona', 'GU': 'Guam', 'MS': 'Mississippi', 'PR': 'Puerto Rico', 'NC': 'North Carolina', 'TX': 'Texas', 'SD': 'South Dakota', 'MP': 'Northern Mariana Islands', 'IA': 'Iowa', 'MO': 'Missouri', 'CT': 'Connecticut', 'WV': 'West Virginia', 'SC': 'South Carolina', 'LA': 'Louisiana', 'KS': 'Kansas', 'NY': 'New York', 'NE': 'Nebraska', 'OK': 'Oklahoma', 'FL': 'Florida', 'CA': 'California', 'CO': 'Colorado', 'PA': 'Pennsylvania', 'DE': 'Delaware', 'NM': 'New Mexico', 'RI': 'Rhode Island', 'MN': 'Minnesota', 'VI': 'Virgin Islands', 'NH': 'New Hampshire', 'MA': 'Massachusetts', 'GA': 'Georgia', 'ND': 'North Dakota', 'VA': 'Virginia'}",
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Tip:  use the `map()` method of pandas (see an example below)"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "import pandas as pd\nequiv = {'7001':'1', '8001':'2', '9001':'3'}\ndf = pd.DataFrame( {\"A\": ['7001', '8001', '9001']} )\ndf[\"B\"] = df[\"A\"].map(equiv)\nprint(df)",
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "      A  B\n0  7001  1\n1  8001  2\n2  9001  3\n"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "def answer_two():\n    pass\n\nanswer_two()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Step3: Merge both datasets. \nFirst check if all the names in the City and State are the same as in the hottest town list. There are some issues. Las Vegas in hootest twon differs from Las Vegas in the health database for instance. \n\nHint: with `df['City'].unique().tolist()` you can create a list of all the City's. With regex and replace you can rename the content. \n\nThen join the datasets on City and State. Drop all the rows from that have NaN in the 'Value' column. \n"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "def answer_three():\n    pass\n\nanswer_three()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Step4: Create a dataset without the hottest towns\n\nNow we need to create the second dataset without the hottest towns. Read the https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.where.html documentation to get some ideas how to do such. \n"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "def answer_four():\n    pass\n\nanswer_four()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Step5: Run the hypothesis-test: \n\n#### Check for normality\nBefore you conduct a hypothesis test to test for mean difference you need to consider a few things. Is the data normal distributed? Plot the data and run some statistical tests to investigate this. If not what is causing skews or outliers? Dive into you data to understand the distribution. Is additional cleaning needed? \n\n#### Check for equal variance\nThe next thing you need to consider is the variance. Is the variance equal or not? Plot data and run some statistical test to investigate this. \n\n#### Hypothesis test\nUse an appropiate hypothesis test to test for difference of Value. \n\n\nFirst run the hypothesis test for the complete dataset. Afterwards repeat the test with a subset of the dataset: the Adult Binge Drinking. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def answer_test():\n    pass\n\nanswer_test()",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Challenge\n\nReview the complete dataset. Formulate yourself a research question. Can you use the data to find a relation? "
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}